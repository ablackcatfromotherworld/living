# 体育数据爬虫实时刷新方案

本项目提供了两种实时刷新方案，让爬虫能够持续运行并保持数据更新。

## 方案一：独立调度器 (推荐)

使用专门的调度器脚本 `scheduler.py`，功能更完善，适合生产环境。

### 基本用法

```bash
# 默认每30分钟刷新一次
python scheduler.py

# 自定义刷新间隔（15分钟）
python scheduler.py --interval 15

# 测试模式运行
python scheduler.py --test

# 指定体育项目ID
python scheduler.py --sport 1

# 组合参数
python scheduler.py --interval 60 --sport 1 --test
```

### 参数说明

- `--interval, -i`: 刷新间隔（分钟），默认30分钟
- `--sport`: 指定体育项目ID
- `--test`: 测试模式，限制并发和数据量

### 功能特点

- ✅ 完善的日志记录（文件+控制台）
- ✅ 优雅停止（Ctrl+C）
- ✅ 错误处理和重试机制
- ✅ 独立进程运行，避免内存泄漏
- ✅ 详细的运行统计信息
- ✅ 支持信号处理（SIGINT, SIGTERM）

## 方案二：扩展原有脚本

在原有的 `run_spider.py` 基础上添加连续运行功能。

### 基本用法

```bash
# 单次运行（原有功能）
python run_spider.py

# 连续运行模式，默认30分钟间隔
python run_spider.py --continuous

# 自定义刷新间隔（20分钟）
python run_spider.py --continuous --interval 20

# 测试模式连续运行
python run_spider.py --continuous --test

# 指定体育项目连续运行
python run_spider.py --continuous --sport 1
```

### 参数说明

- `--continuous, -c`: 启用连续运行模式
- `--interval, -i`: 连续运行模式下的刷新间隔（分钟）
- `--sport`: 指定体育项目ID
- `--test`: 测试模式

## 使用建议

### 生产环境推荐

**使用方案一（scheduler.py）**，因为：

1. **更好的日志管理**：自动按日期分割日志文件
2. **更强的稳定性**：独立进程避免内存累积
3. **更完善的监控**：详细的运行统计和错误处理
4. **更好的维护性**：专门的调度逻辑，便于扩展

```bash
# 生产环境推荐配置
python scheduler.py --interval 30
```

### 开发测试推荐

**使用方案二（run_spider.py --continuous）**，因为：

1. **快速启动**：基于现有脚本，无需额外配置
2. **简单调试**：输出直接显示在控制台
3. **灵活切换**：可以随时在单次和连续模式间切换

```bash
# 开发测试推荐配置
python run_spider.py --continuous --test --interval 5
```

## 停止运行

两种方案都支持优雅停止：

- **键盘中断**：按 `Ctrl+C`
- **系统信号**：发送 SIGINT 或 SIGTERM 信号

停止时会：
1. 等待当前爬取任务完成
2. 显示运行统计信息
3. 清理资源并退出

## 日志文件

### scheduler.py 日志

- 位置：`logs/scheduler_YYYYMMDD.log`
- 格式：时间戳 + 日志级别 + 消息
- 自动按日期分割

### run_spider.py 日志

- 输出到控制台
- 包含运行时间和状态信息

## 监控建议

1. **定期检查日志文件**，关注错误信息
2. **监控系统资源**，确保内存和CPU使用正常
3. **设置告警机制**，在爬虫异常停止时及时通知
4. **定期备份数据**，防止数据丢失

## 故障排除

### 常见问题

1. **爬虫启动失败**
   - 检查数据库连接配置
   - 确认依赖包已安装
   - 查看错误日志详情

2. **内存使用过高**
   - 使用方案一（独立进程）
   - 减少并发请求数
   - 增加刷新间隔

3. **网络连接问题**
   - 检查网络连接
   - 调整请求延迟
   - 配置代理（如需要）

4. **数据库连接超时**
   - 检查数据库服务状态
   - 调整连接池配置
   - 增加连接超时时间

### 调试模式

```bash
# 启用测试模式，限制数据量便于调试
python scheduler.py --test --interval 1

# 或
python run_spider.py --continuous --test --interval 1
```

## 性能优化

1. **合理设置刷新间隔**：根据数据更新频率调整
2. **使用测试模式**：开发时限制数据量
3. **监控资源使用**：定期检查内存和CPU
4. **优化数据库操作**：使用批量插入，优化索引

## 扩展功能

可以根据需要扩展以下功能：

1. **邮件通知**：爬取完成或异常时发送邮件
2. **数据统计**：记录每次爬取的数据量
3. **健康检查**：定期检查爬虫状态
4. **配置文件**：使用配置文件管理参数
5. **Web界面**：提供Web界面监控和控制

---

选择适合你的方案，开始享受自动化的数据更新吧！🚀